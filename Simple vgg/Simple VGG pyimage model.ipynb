{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "            \n",
    "\t\t# CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\t\t# (CONV => RELU) * 2 => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\t\t# (CONV => RELU) * 3 => POOL layer set\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        \n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(\"F:\\\\STUDY MATERIAL\\\\DEEP LEARNING\\\\keras-tutorial\\\\keras-tutorial\\\\animals\")))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, resize the image to be 32x32 pixels (ignoring\n",
    "\t# aspect ratio), flatten the image into 32x32x3=3072 pixel image\n",
    "\t# into a list, and store the image in the data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (64, 64))\n",
    "\tdata.append(image)\n",
    "\n",
    "\t# extract the class label from the image path and update the\n",
    "\t# labels list\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\tlabels.append(label)\n",
    "    \n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=64, height=64, depth=3,\n",
    "\tclasses=len(lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/75\n",
      "70/70 [==============================] - 172s 2s/step - loss: 1.3359 - accuracy: 0.5293 - val_loss: 1.8278 - val_accuracy: 0.3147\n",
      "Epoch 2/75\n",
      "70/70 [==============================] - 114s 2s/step - loss: 1.0596 - accuracy: 0.5766 - val_loss: 2.1609 - val_accuracy: 0.3467\n",
      "Epoch 3/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.8987 - accuracy: 0.5924 - val_loss: 2.2223 - val_accuracy: 0.3187\n",
      "Epoch 4/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.8203 - accuracy: 0.6253 - val_loss: 1.0730 - val_accuracy: 0.4093\n",
      "Epoch 5/75\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.7725 - accuracy: 0.6398 - val_loss: 1.4263 - val_accuracy: 0.3693\n",
      "Epoch 6/75\n",
      "70/70 [==============================] - 114s 2s/step - loss: 0.7223 - accuracy: 0.6506 - val_loss: 0.8949 - val_accuracy: 0.5893\n",
      "Epoch 7/75\n",
      "70/70 [==============================] - 119s 2s/step - loss: 0.6932 - accuracy: 0.6614 - val_loss: 0.6959 - val_accuracy: 0.6747\n",
      "Epoch 8/75\n",
      "70/70 [==============================] - 122s 2s/step - loss: 0.7075 - accuracy: 0.6632 - val_loss: 0.6521 - val_accuracy: 0.7013\n",
      "Epoch 9/75\n",
      "70/70 [==============================] - 109s 2s/step - loss: 0.6808 - accuracy: 0.6767 - val_loss: 0.6090 - val_accuracy: 0.7160\n",
      "Epoch 10/75\n",
      "70/70 [==============================] - 158s 2s/step - loss: 0.6589 - accuracy: 0.6894 - val_loss: 0.9195 - val_accuracy: 0.6213\n",
      "Epoch 11/75\n",
      "70/70 [==============================] - 114s 2s/step - loss: 0.6761 - accuracy: 0.6826 - val_loss: 0.6844 - val_accuracy: 0.7013\n",
      "Epoch 12/75\n",
      "70/70 [==============================] - 108s 2s/step - loss: 0.6442 - accuracy: 0.6889 - val_loss: 0.6751 - val_accuracy: 0.6747\n",
      "Epoch 13/75\n",
      "70/70 [==============================] - 106s 2s/step - loss: 0.6320 - accuracy: 0.6961 - val_loss: 0.7103 - val_accuracy: 0.7120\n",
      "Epoch 14/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.6377 - accuracy: 0.6916 - val_loss: 0.6988 - val_accuracy: 0.7200\n",
      "Epoch 15/75\n",
      "70/70 [==============================] - 99s 1s/step - loss: 0.5816 - accuracy: 0.7236 - val_loss: 0.7363 - val_accuracy: 0.6853\n",
      "Epoch 16/75\n",
      "70/70 [==============================] - 103s 1s/step - loss: 0.6188 - accuracy: 0.7085 - val_loss: 0.5987 - val_accuracy: 0.7520\n",
      "Epoch 17/75\n",
      "70/70 [==============================] - 102s 1s/step - loss: 0.5941 - accuracy: 0.7254 - val_loss: 0.5957 - val_accuracy: 0.7227\n",
      "Epoch 18/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.5861 - accuracy: 0.7214 - val_loss: 0.6116 - val_accuracy: 0.7520\n",
      "Epoch 19/75\n",
      "70/70 [==============================] - 102s 1s/step - loss: 0.6095 - accuracy: 0.7020 - val_loss: 0.6126 - val_accuracy: 0.7360\n",
      "Epoch 20/75\n",
      "70/70 [==============================] - 103s 1s/step - loss: 0.5717 - accuracy: 0.7246 - val_loss: 0.6333 - val_accuracy: 0.7307\n",
      "Epoch 21/75\n",
      "70/70 [==============================] - 104s 1s/step - loss: 0.6103 - accuracy: 0.7054 - val_loss: 0.5852 - val_accuracy: 0.7493\n",
      "Epoch 22/75\n",
      "70/70 [==============================] - 115s 2s/step - loss: 0.5489 - accuracy: 0.7348 - val_loss: 0.5743 - val_accuracy: 0.7387\n",
      "Epoch 23/75\n",
      "70/70 [==============================] - 120s 2s/step - loss: 0.5776 - accuracy: 0.7263 - val_loss: 0.6364 - val_accuracy: 0.7427\n",
      "Epoch 24/75\n",
      "70/70 [==============================] - 110s 2s/step - loss: 0.5786 - accuracy: 0.7331 - val_loss: 0.6788 - val_accuracy: 0.7160\n",
      "Epoch 25/75\n",
      "70/70 [==============================] - 149s 2s/step - loss: 0.5507 - accuracy: 0.7466 - val_loss: 0.5904 - val_accuracy: 0.7413\n",
      "Epoch 26/75\n",
      "70/70 [==============================] - 252s 4s/step - loss: 0.5514 - accuracy: 0.7348 - val_loss: 0.5941 - val_accuracy: 0.7520\n",
      "Epoch 27/75\n",
      "70/70 [==============================] - 229s 3s/step - loss: 0.5712 - accuracy: 0.7291 - val_loss: 0.6053 - val_accuracy: 0.7453\n",
      "Epoch 28/75\n",
      "70/70 [==============================] - 117s 2s/step - loss: 0.5684 - accuracy: 0.7362 - val_loss: 0.5702 - val_accuracy: 0.7640\n",
      "Epoch 29/75\n",
      "70/70 [==============================] - 104s 1s/step - loss: 0.5111 - accuracy: 0.7534 - val_loss: 0.6203 - val_accuracy: 0.7280\n",
      "Epoch 30/75\n",
      "70/70 [==============================] - 104s 1s/step - loss: 0.5289 - accuracy: 0.7520 - val_loss: 0.5909 - val_accuracy: 0.7573\n",
      "Epoch 31/75\n",
      "70/70 [==============================] - 107s 2s/step - loss: 0.5490 - accuracy: 0.7435 - val_loss: 0.5574 - val_accuracy: 0.7613\n",
      "Epoch 32/75\n",
      "70/70 [==============================] - 106s 2s/step - loss: 0.5196 - accuracy: 0.7660 - val_loss: 0.5767 - val_accuracy: 0.7547\n",
      "Epoch 33/75\n",
      "70/70 [==============================] - 101s 1s/step - loss: 0.5132 - accuracy: 0.7589 - val_loss: 0.6337 - val_accuracy: 0.7280\n",
      "Epoch 34/75\n",
      "70/70 [==============================] - 100s 1s/step - loss: 0.5321 - accuracy: 0.7618 - val_loss: 0.5513 - val_accuracy: 0.7587\n",
      "Epoch 35/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.5025 - accuracy: 0.7732 - val_loss: 0.5627 - val_accuracy: 0.7667\n",
      "Epoch 36/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.5209 - accuracy: 0.7589 - val_loss: 0.6011 - val_accuracy: 0.7547\n",
      "Epoch 37/75\n",
      "70/70 [==============================] - 101s 1s/step - loss: 0.5062 - accuracy: 0.7683 - val_loss: 0.6027 - val_accuracy: 0.7440\n",
      "Epoch 38/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.5076 - accuracy: 0.7577 - val_loss: 0.6214 - val_accuracy: 0.7613\n",
      "Epoch 39/75\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.5101 - accuracy: 0.7579 - val_loss: 0.5653 - val_accuracy: 0.7627\n",
      "Epoch 40/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.5304 - accuracy: 0.7471 - val_loss: 0.6867 - val_accuracy: 0.7467\n",
      "Epoch 41/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.4870 - accuracy: 0.7746 - val_loss: 0.6086 - val_accuracy: 0.7573\n",
      "Epoch 42/75\n",
      "70/70 [==============================] - 103s 1s/step - loss: 0.5274 - accuracy: 0.7597 - val_loss: 0.5898 - val_accuracy: 0.7520\n",
      "Epoch 43/75\n",
      "70/70 [==============================] - 104s 1s/step - loss: 0.4875 - accuracy: 0.7845 - val_loss: 0.6815 - val_accuracy: 0.7333\n",
      "Epoch 44/75\n",
      "70/70 [==============================] - 101s 1s/step - loss: 0.5250 - accuracy: 0.7597 - val_loss: 0.6106 - val_accuracy: 0.7507\n",
      "Epoch 45/75\n",
      "70/70 [==============================] - 105s 1s/step - loss: 0.4954 - accuracy: 0.7813 - val_loss: 0.9398 - val_accuracy: 0.6813\n",
      "Epoch 46/75\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.4790 - accuracy: 0.7741 - val_loss: 0.6243 - val_accuracy: 0.7573\n",
      "Epoch 47/75\n",
      "70/70 [==============================] - 114s 2s/step - loss: 0.5135 - accuracy: 0.7683 - val_loss: 0.6678 - val_accuracy: 0.7373\n",
      "Epoch 48/75\n",
      "70/70 [==============================] - 99s 1s/step - loss: 0.4965 - accuracy: 0.7612 - val_loss: 0.5434 - val_accuracy: 0.7667\n",
      "Epoch 49/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.4699 - accuracy: 0.7876 - val_loss: 0.5950 - val_accuracy: 0.7547\n",
      "Epoch 50/75\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.4936 - accuracy: 0.7719 - val_loss: 0.7723 - val_accuracy: 0.7040\n",
      "Epoch 51/75\n",
      "70/70 [==============================] - 100s 1s/step - loss: 0.4647 - accuracy: 0.8018 - val_loss: 0.5833 - val_accuracy: 0.7600\n",
      "Epoch 52/75\n",
      "70/70 [==============================] - 109s 2s/step - loss: 0.4832 - accuracy: 0.7804 - val_loss: 0.6522 - val_accuracy: 0.7453\n",
      "Epoch 53/75\n",
      "70/70 [==============================] - 103s 1s/step - loss: 0.4701 - accuracy: 0.7777 - val_loss: 0.5962 - val_accuracy: 0.7547\n",
      "Epoch 54/75\n",
      "70/70 [==============================] - 106s 2s/step - loss: 0.4677 - accuracy: 0.7831 - val_loss: 0.6038 - val_accuracy: 0.7627\n",
      "Epoch 55/75\n",
      "70/70 [==============================] - 122s 2s/step - loss: 0.4929 - accuracy: 0.7786 - val_loss: 0.5777 - val_accuracy: 0.7547\n",
      "Epoch 56/75\n",
      "70/70 [==============================] - 111s 2s/step - loss: 0.4656 - accuracy: 0.7867 - val_loss: 0.5837 - val_accuracy: 0.7520\n",
      "Epoch 57/75\n",
      "70/70 [==============================] - 114s 2s/step - loss: 0.4689 - accuracy: 0.7876 - val_loss: 0.5660 - val_accuracy: 0.7720\n",
      "Epoch 58/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 104s 1s/step - loss: 0.4620 - accuracy: 0.7994 - val_loss: 0.7027 - val_accuracy: 0.7307\n",
      "Epoch 59/75\n",
      "70/70 [==============================] - 108s 2s/step - loss: 0.4438 - accuracy: 0.8066 - val_loss: 0.5498 - val_accuracy: 0.7693\n",
      "Epoch 60/75\n",
      "70/70 [==============================] - 109s 2s/step - loss: 0.4527 - accuracy: 0.7976 - val_loss: 0.5197 - val_accuracy: 0.7840\n",
      "Epoch 61/75\n",
      "70/70 [==============================] - 122s 2s/step - loss: 0.4667 - accuracy: 0.8037 - val_loss: 0.7257 - val_accuracy: 0.7280\n",
      "Epoch 62/75\n",
      "70/70 [==============================] - 126s 2s/step - loss: 0.4710 - accuracy: 0.7982 - val_loss: 0.5417 - val_accuracy: 0.7653\n",
      "Epoch 63/75\n",
      "70/70 [==============================] - 135s 2s/step - loss: 0.4485 - accuracy: 0.8039 - val_loss: 0.6478 - val_accuracy: 0.7587\n",
      "Epoch 64/75\n",
      "70/70 [==============================] - 124s 2s/step - loss: 0.4518 - accuracy: 0.7962 - val_loss: 0.7512 - val_accuracy: 0.7253\n",
      "Epoch 65/75\n",
      "70/70 [==============================] - 126s 2s/step - loss: 0.4745 - accuracy: 0.7885 - val_loss: 0.6924 - val_accuracy: 0.7427\n",
      "Epoch 66/75\n",
      "70/70 [==============================] - 132s 2s/step - loss: 0.4400 - accuracy: 0.8075 - val_loss: 0.6036 - val_accuracy: 0.7627\n",
      "Epoch 67/75\n",
      "70/70 [==============================] - 125s 2s/step - loss: 0.4259 - accuracy: 0.8061 - val_loss: 0.7286 - val_accuracy: 0.7160\n",
      "Epoch 68/75\n",
      "70/70 [==============================] - 126s 2s/step - loss: 0.4287 - accuracy: 0.8188 - val_loss: 0.6144 - val_accuracy: 0.7707\n",
      "Epoch 69/75\n",
      "70/70 [==============================] - 126s 2s/step - loss: 0.4442 - accuracy: 0.8070 - val_loss: 0.5708 - val_accuracy: 0.7733\n",
      "Epoch 70/75\n",
      "70/70 [==============================] - 128s 2s/step - loss: 0.4458 - accuracy: 0.7926 - val_loss: 0.7221 - val_accuracy: 0.7360\n",
      "Epoch 71/75\n",
      "70/70 [==============================] - 137s 2s/step - loss: 0.4435 - accuracy: 0.8034 - val_loss: 0.7551 - val_accuracy: 0.7133\n",
      "Epoch 72/75\n",
      "70/70 [==============================] - 151s 2s/step - loss: 0.4572 - accuracy: 0.7894 - val_loss: 0.6888 - val_accuracy: 0.7453\n",
      "Epoch 73/75\n",
      "70/70 [==============================] - 147s 2s/step - loss: 0.4422 - accuracy: 0.7994 - val_loss: 0.5767 - val_accuracy: 0.7640\n",
      "Epoch 74/75\n",
      "70/70 [==============================] - 141s 2s/step - loss: 0.4442 - accuracy: 0.7989 - val_loss: 0.5641 - val_accuracy: 0.7787\n",
      "Epoch 75/75\n",
      "70/70 [==============================] - 152s 2s/step - loss: 0.4289 - accuracy: 0.8093 - val_loss: 0.5457 - val_accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    "\n",
    "# initialize the model and optimizer (you'll want to use\n",
    "# binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.68      0.77      0.73       236\n",
      "        dogs       0.72      0.61      0.67       236\n",
      "       panda       0.90      0.92      0.91       278\n",
      "\n",
      "    accuracy                           0.78       750\n",
      "   macro avg       0.77      0.77      0.77       750\n",
      "weighted avg       0.78      0.78      0.78       750\n",
      "\n",
      "[INFO] serializing network and label binarizer...\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"F:\\\\STUDY MATERIAL\\\\DEEP LEARNING\\\\keras-tutorial\\\\keras-tutorial\\\\My Codes\\\\Simple vgg\\\\figure.jpg\")\n",
    "\n",
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"F:\\\\STUDY MATERIAL\\\\DEEP LEARNING\\\\keras-tutorial\\\\keras-tutorial\\\\My Codes\\\\Simple vgg\\\\model\")\n",
    "f = open(\"F:\\\\STUDY MATERIAL\\\\DEEP LEARNING\\\\keras-tutorial\\\\keras-tutorial\\\\My Codes\\\\Simple vgg\\\\label\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
